{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWMEuhJWP1kSk7Ua7J8d33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mearoche/text-mining-tutorial/blob/master/Ass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Data import and preparation/clean up"
      ],
      "metadata": {
        "id": "LyNS9SNOZa6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up"
      ],
      "metadata": {
        "id": "_Gk76RJ1Zf7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Colab: \n",
        "# 1. First CHANGE RUNTIME TYPE to GPU \n",
        "# 2. Then run install commands commented out below\n",
        "# 3. Then RESTART RUNTIME\n",
        "# 4. Then run git clone command commented out below\n",
        "# 5. Then run all the other cells"
      ],
      "metadata": {
        "id": "cBgkhw8FZjlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "#!pip install --upgrade jax==0.2.3 jaxlib==0.1.56+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "#!pip install --upgrade numpyro==0.4.1\n",
        "#!pip install flashtext\n",
        "#!pip install contractions\n",
        "#!pip install lda\n",
        "#!pip install --upgrade spacy==2.2.4\n",
        "#!pip install --upgrade folium==0.2.1\n",
        "#!pip install topic-modelling-tools"
      ],
      "metadata": {
        "id": "S7LmlVB9Zlyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart RUNTIME after installing packages!"
      ],
      "metadata": {
        "id": "PWo9ez2BZplT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning GitHub (to do only once! Then comment it)\n",
        "#!git clone https://mearoche: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@github.com/mearoche/text-mining-tutorial.git"
      ],
      "metadata": {
        "id": "u3NVMfWCZqQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd text-mining-tutorial"
      ],
      "metadata": {
        "id": "BhB6r4lsZrvn",
        "outputId": "4c503c1c-9b0e-4075-a068-e42e23904d97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-mining-tutorial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the directory contains the growthdata.csv file\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7VgcRs-ZusU",
        "outputId": "8bfaa3a9-1674-423f-a9dc-ef184a99dd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ass3.ipynb\tfinal_output_agg.csv\ttopic_description.csv\n",
            "df_ranking.csv\tREADME.md\t\ttt.csv\n",
            "dict.csv\trequirements.txt\ttutorial_notebook.ipynb\n",
            "dt.csv\t\tspeech_data_extend.txt\ttutorial.py\n",
            "dt_query.csv\ttfidf_ranking.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "\n",
        "# JAX\n",
        "import jax\n",
        "from jax import random, vmap, jit\n",
        "import jax.numpy as jnp\n",
        "import jax.nn as nn\n",
        "from jax.random import PRNGKey as Key\n",
        "\n",
        "# Panda\n",
        "import pandas as pd\n",
        "\n",
        "# Numpyro\n",
        "import numpyro\n",
        "import numpy as np\n",
        "numpyro.set_platform(\"cpu\")\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS, log_likelihood\n",
        "import numpyro.infer.util \n",
        "from numpyro.primitives import deterministic\n",
        "from numpyro.handlers import condition, substitute, block\n",
        "\n",
        "# Matplot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Spacy\n",
        "import spacy\n",
        "spacy.load('en_core_web_sm')\n",
        "\n",
        "# LDA\n",
        "import lda\n",
        "\n",
        "# Others\n",
        "import time\n",
        "import string\n",
        "import topicmodels\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sys\n",
        "sys.path.append('../pymodules')"
      ],
      "metadata": {
        "id": "ivVCF7D3ZxdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import data"
      ],
      "metadata": {
        "id": "7HS0EAxyaTZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import US Presidential State-of-the-Union addresses from 1945 onwards\n",
        "data = pd.read_table(\"speech_data_extend.txt\", encoding=\"utf-8\")\n",
        "data = data[data.year >= 1945]"
      ],
      "metadata": {
        "id": "2P4UpG0taVEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of documents in the dataset\n",
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcEcHHzogfxj",
        "outputId": "f3f18941-6d85-48d8-82f6-64109e5753c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10260"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. LDA"
      ],
      "metadata": {
        "id": "yPXDOkhLjWz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing"
      ],
      "metadata": {
        "id": "1awPe-dbjYqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I define docsobj, tokenized\n",
        "docsobj = topicmodels.RawDocs(data.speech, \"long\")"
      ],
      "metadata": {
        "id": "b_G48Ep9ja6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the stop words list, from http://snowball.tartarus.org/algorithms/english/stop.txt (long version)\n",
        "docsobj.stopwords"
      ],
      "metadata": {
        "id": "0VzS5gFsnafO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56d26f0-2e41-4288-9998-b47bb0591dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'also',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'are',\n",
              " 'as',\n",
              " 'at',\n",
              " 'back',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'could',\n",
              " 'did',\n",
              " 'do',\n",
              " 'does',\n",
              " 'doing',\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'few',\n",
              " 'first',\n",
              " 'five',\n",
              " 'for',\n",
              " 'four',\n",
              " 'from',\n",
              " 'further',\n",
              " 'get',\n",
              " 'go',\n",
              " 'goes',\n",
              " 'had',\n",
              " 'has',\n",
              " 'have',\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'high',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'however',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'least',\n",
              " 'less',\n",
              " 'like',\n",
              " 'long',\n",
              " 'made',\n",
              " 'make',\n",
              " 'many',\n",
              " 'me',\n",
              " 'more',\n",
              " 'most',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'never',\n",
              " 'new',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'of',\n",
              " 'off',\n",
              " 'old',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'ought',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'put',\n",
              " 'said',\n",
              " 'same',\n",
              " 'say',\n",
              " 'says',\n",
              " 'second',\n",
              " 'see',\n",
              " 'seen',\n",
              " 'she',\n",
              " 'should',\n",
              " 'since',\n",
              " 'so',\n",
              " 'some',\n",
              " 'still',\n",
              " 'such',\n",
              " 'take',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'three',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'two',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'us',\n",
              " 'very',\n",
              " 'was',\n",
              " 'way',\n",
              " 'we',\n",
              " 'well',\n",
              " 'were',\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'with',\n",
              " 'would',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we want to focus on words and not tokens, I will clean the tokens (all non-alphabetic and numeric tokens), and remove those with length less than 1\n",
        "docsobj.token_clean(1)"
      ],
      "metadata": {
        "id": "nSzOw-AQnxRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I remove the stopwords from docsobj.tokens\n",
        "docsobj.stopword_remove(\"tokens\")"
      ],
      "metadata": {
        "id": "5FISLTBtoYVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to group together words that are grammatically different but thematically identical, i.e. stemming, using Porter stemmer\n",
        "docsobj.stem()\n",
        "docsobj.stopword_remove(\"stems\") # I again remove stopwords as stemmed forms of tokens may be in the stopword list"
      ],
      "metadata": {
        "id": "qsBln3ewonUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I use TF-IDF on each stem to measure informativeness (to identify common words and rare words)\n",
        "docsobj.term_rank(\"stems\") # Outcome is 2 csv files: df_ranking.csv ranks each stem according to its document frequency, and tfidf_ranking.csv ranks each stem according to the tf-idf measure."
      ],
      "metadata": {
        "id": "D1d55d8mpI7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the ranking of the TF-IDF to explore a potential cutoff value\n",
        "plt.plot([x[1] for x in docsobj.tfidf_ranking])"
      ],
      "metadata": {
        "id": "MYC_lqaEpvPj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dd86e429-ad04-492d-bdec-34fa16a77182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3958e12d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I take as cutoff 5,000. It seems reasonable according to the above plot."
      ],
      "metadata": {
        "id": "7mAEIPF8qkyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I now drop the stems below this cutoff\n",
        "cutoff = 5000\n",
        "docsobj.rank_remove(\"tfidf\",\"stems\",docsobj.tfidf_ranking[cutoff][1])\n",
        "all_stems = [s for d in docsobj.stems for s in d]"
      ],
      "metadata": {
        "id": "nqh6Fyauqryp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I check number of unique stems\n",
        "print(len(set(all_stems)))\n",
        "V = len(set(all_stems))\n",
        "# Check number of total stems\n",
        "print(len(all_stems))"
      ],
      "metadata": {
        "id": "Fm9QMEbarCSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c264878-5bc3-4fc1-d8ef-42d56d897566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4918\n",
            "268763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I obtain 4,918 unique stems and 268,763 total stems. I can now estimate my LDA."
      ],
      "metadata": {
        "id": "6o0cXUKmrO0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estimations"
      ],
      "metadata": {
        "id": "xF8hrugGpNUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will estimate an LDA on individual paragraphs using the collapsed Gibbs sampling algorithm of Griffiths and Steyvers (2004)."
      ],
      "metadata": {
        "id": "L3QakVDVUQXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I choose the number of topics (arbitrary choice)\n",
        "topics = 20\n",
        "ldaobj = topicmodels.LDA.LDAGibbs(docsobj.stems,topics)"
      ],
      "metadata": {
        "id": "03LSAanpUaqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I choose the hyperparameters of the Dirichlet priors, here I follow Griffiths and Steyvers (2004)\n",
        "print(ldaobj.K) # number of topic, arbitrary, here K = 20\n",
        "print(ldaobj.alpha) # hyperparameter for document-topic distribution, automatically defined as 50/K, with K the number of topics\n",
        "print(50/topics) # checked and all good\n",
        "print(ldaobj.beta) # hyperparameter for topics, automatically defined as 200/V, with V the number of unique vocabulary elements\n",
        "print(200/V) # checked and all good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbNY-p-2UuWR",
        "outputId": "5f8a388a-43d5-486b-9a7f-7eb4f8b83615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "2.5\n",
            "2.5\n",
            "0.040666937779585195\n",
            "0.040666937779585195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I will sample.\n",
        "\n",
        "To do so, I have to decide on three parameters:\n",
        "\n",
        "\n",
        "1.   Number of iterations I want the chain to burn in before beginning to sample (A)\n",
        "2.   Thinning interval: the number of iterations to let the chain run between samples (B)\n",
        "3.   Number of samples to take (C)\n",
        "\n",
        "Total number of iterations = A + B x C\n",
        "\n"
      ],
      "metadata": {
        "id": "3TWjTuErXLYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I select arbitrary values for A, B, and C keeping in mind that I do not want the code to take too long to run\n",
        "A = 0 \n",
        "B = 50\n",
        "C = 30\n",
        "ldaobj.sample(A,B,C) # Here 1500 iterations\n",
        "ldaobj.perplexity() # To check goodness-of-fit of each of the C samples (the lower the value the better the fit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ttHEcrWi75",
        "outputId": "2a19f87d-7fe4-4066-cdb1-fef02924baf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10 of (collapsed) Gibbs sampling\n",
            "Iteration 20 of (collapsed) Gibbs sampling\n",
            "Iteration 30 of (collapsed) Gibbs sampling\n",
            "Iteration 40 of (collapsed) Gibbs sampling\n",
            "Iteration 50 of (collapsed) Gibbs sampling\n",
            "Iteration 60 of (collapsed) Gibbs sampling\n",
            "Iteration 70 of (collapsed) Gibbs sampling\n",
            "Iteration 80 of (collapsed) Gibbs sampling\n",
            "Iteration 90 of (collapsed) Gibbs sampling\n",
            "Iteration 100 of (collapsed) Gibbs sampling\n",
            "Iteration 110 of (collapsed) Gibbs sampling\n",
            "Iteration 120 of (collapsed) Gibbs sampling\n",
            "Iteration 130 of (collapsed) Gibbs sampling\n",
            "Iteration 140 of (collapsed) Gibbs sampling\n",
            "Iteration 150 of (collapsed) Gibbs sampling\n",
            "Iteration 160 of (collapsed) Gibbs sampling\n",
            "Iteration 170 of (collapsed) Gibbs sampling\n",
            "Iteration 180 of (collapsed) Gibbs sampling\n",
            "Iteration 190 of (collapsed) Gibbs sampling\n",
            "Iteration 200 of (collapsed) Gibbs sampling\n",
            "Iteration 210 of (collapsed) Gibbs sampling\n",
            "Iteration 220 of (collapsed) Gibbs sampling\n",
            "Iteration 230 of (collapsed) Gibbs sampling\n",
            "Iteration 240 of (collapsed) Gibbs sampling\n",
            "Iteration 250 of (collapsed) Gibbs sampling\n",
            "Iteration 260 of (collapsed) Gibbs sampling\n",
            "Iteration 270 of (collapsed) Gibbs sampling\n",
            "Iteration 280 of (collapsed) Gibbs sampling\n",
            "Iteration 290 of (collapsed) Gibbs sampling\n",
            "Iteration 300 of (collapsed) Gibbs sampling\n",
            "Iteration 310 of (collapsed) Gibbs sampling\n",
            "Iteration 320 of (collapsed) Gibbs sampling\n",
            "Iteration 330 of (collapsed) Gibbs sampling\n",
            "Iteration 340 of (collapsed) Gibbs sampling\n",
            "Iteration 350 of (collapsed) Gibbs sampling\n",
            "Iteration 360 of (collapsed) Gibbs sampling\n",
            "Iteration 370 of (collapsed) Gibbs sampling\n",
            "Iteration 380 of (collapsed) Gibbs sampling\n",
            "Iteration 390 of (collapsed) Gibbs sampling\n",
            "Iteration 400 of (collapsed) Gibbs sampling\n",
            "Iteration 410 of (collapsed) Gibbs sampling\n",
            "Iteration 420 of (collapsed) Gibbs sampling\n",
            "Iteration 430 of (collapsed) Gibbs sampling\n",
            "Iteration 440 of (collapsed) Gibbs sampling\n",
            "Iteration 450 of (collapsed) Gibbs sampling\n",
            "Iteration 460 of (collapsed) Gibbs sampling\n",
            "Iteration 470 of (collapsed) Gibbs sampling\n",
            "Iteration 480 of (collapsed) Gibbs sampling\n",
            "Iteration 490 of (collapsed) Gibbs sampling\n",
            "Iteration 500 of (collapsed) Gibbs sampling\n",
            "Iteration 510 of (collapsed) Gibbs sampling\n",
            "Iteration 520 of (collapsed) Gibbs sampling\n",
            "Iteration 530 of (collapsed) Gibbs sampling\n",
            "Iteration 540 of (collapsed) Gibbs sampling\n",
            "Iteration 550 of (collapsed) Gibbs sampling\n",
            "Iteration 560 of (collapsed) Gibbs sampling\n",
            "Iteration 570 of (collapsed) Gibbs sampling\n",
            "Iteration 580 of (collapsed) Gibbs sampling\n",
            "Iteration 590 of (collapsed) Gibbs sampling\n",
            "Iteration 600 of (collapsed) Gibbs sampling\n",
            "Iteration 610 of (collapsed) Gibbs sampling\n",
            "Iteration 620 of (collapsed) Gibbs sampling\n",
            "Iteration 630 of (collapsed) Gibbs sampling\n",
            "Iteration 640 of (collapsed) Gibbs sampling\n",
            "Iteration 650 of (collapsed) Gibbs sampling\n",
            "Iteration 660 of (collapsed) Gibbs sampling\n",
            "Iteration 670 of (collapsed) Gibbs sampling\n",
            "Iteration 680 of (collapsed) Gibbs sampling\n",
            "Iteration 690 of (collapsed) Gibbs sampling\n",
            "Iteration 700 of (collapsed) Gibbs sampling\n",
            "Iteration 710 of (collapsed) Gibbs sampling\n",
            "Iteration 720 of (collapsed) Gibbs sampling\n",
            "Iteration 730 of (collapsed) Gibbs sampling\n",
            "Iteration 740 of (collapsed) Gibbs sampling\n",
            "Iteration 750 of (collapsed) Gibbs sampling\n",
            "Iteration 760 of (collapsed) Gibbs sampling\n",
            "Iteration 770 of (collapsed) Gibbs sampling\n",
            "Iteration 780 of (collapsed) Gibbs sampling\n",
            "Iteration 790 of (collapsed) Gibbs sampling\n",
            "Iteration 800 of (collapsed) Gibbs sampling\n",
            "Iteration 810 of (collapsed) Gibbs sampling\n",
            "Iteration 820 of (collapsed) Gibbs sampling\n",
            "Iteration 830 of (collapsed) Gibbs sampling\n",
            "Iteration 840 of (collapsed) Gibbs sampling\n",
            "Iteration 850 of (collapsed) Gibbs sampling\n",
            "Iteration 860 of (collapsed) Gibbs sampling\n",
            "Iteration 870 of (collapsed) Gibbs sampling\n",
            "Iteration 880 of (collapsed) Gibbs sampling\n",
            "Iteration 890 of (collapsed) Gibbs sampling\n",
            "Iteration 900 of (collapsed) Gibbs sampling\n",
            "Iteration 910 of (collapsed) Gibbs sampling\n",
            "Iteration 920 of (collapsed) Gibbs sampling\n",
            "Iteration 930 of (collapsed) Gibbs sampling\n",
            "Iteration 940 of (collapsed) Gibbs sampling\n",
            "Iteration 950 of (collapsed) Gibbs sampling\n",
            "Iteration 960 of (collapsed) Gibbs sampling\n",
            "Iteration 970 of (collapsed) Gibbs sampling\n",
            "Iteration 980 of (collapsed) Gibbs sampling\n",
            "Iteration 990 of (collapsed) Gibbs sampling\n",
            "Iteration 1000 of (collapsed) Gibbs sampling\n",
            "Iteration 1010 of (collapsed) Gibbs sampling\n",
            "Iteration 1020 of (collapsed) Gibbs sampling\n",
            "Iteration 1030 of (collapsed) Gibbs sampling\n",
            "Iteration 1040 of (collapsed) Gibbs sampling\n",
            "Iteration 1050 of (collapsed) Gibbs sampling\n",
            "Iteration 1060 of (collapsed) Gibbs sampling\n",
            "Iteration 1070 of (collapsed) Gibbs sampling\n",
            "Iteration 1080 of (collapsed) Gibbs sampling\n",
            "Iteration 1090 of (collapsed) Gibbs sampling\n",
            "Iteration 1100 of (collapsed) Gibbs sampling\n",
            "Iteration 1110 of (collapsed) Gibbs sampling\n",
            "Iteration 1120 of (collapsed) Gibbs sampling\n",
            "Iteration 1130 of (collapsed) Gibbs sampling\n",
            "Iteration 1140 of (collapsed) Gibbs sampling\n",
            "Iteration 1150 of (collapsed) Gibbs sampling\n",
            "Iteration 1160 of (collapsed) Gibbs sampling\n",
            "Iteration 1170 of (collapsed) Gibbs sampling\n",
            "Iteration 1180 of (collapsed) Gibbs sampling\n",
            "Iteration 1190 of (collapsed) Gibbs sampling\n",
            "Iteration 1200 of (collapsed) Gibbs sampling\n",
            "Iteration 1210 of (collapsed) Gibbs sampling\n",
            "Iteration 1220 of (collapsed) Gibbs sampling\n",
            "Iteration 1230 of (collapsed) Gibbs sampling\n",
            "Iteration 1240 of (collapsed) Gibbs sampling\n",
            "Iteration 1250 of (collapsed) Gibbs sampling\n",
            "Iteration 1260 of (collapsed) Gibbs sampling\n",
            "Iteration 1270 of (collapsed) Gibbs sampling\n",
            "Iteration 1280 of (collapsed) Gibbs sampling\n",
            "Iteration 1290 of (collapsed) Gibbs sampling\n",
            "Iteration 1300 of (collapsed) Gibbs sampling\n",
            "Iteration 1310 of (collapsed) Gibbs sampling\n",
            "Iteration 1320 of (collapsed) Gibbs sampling\n",
            "Iteration 1330 of (collapsed) Gibbs sampling\n",
            "Iteration 1340 of (collapsed) Gibbs sampling\n",
            "Iteration 1350 of (collapsed) Gibbs sampling\n",
            "Iteration 1360 of (collapsed) Gibbs sampling\n",
            "Iteration 1370 of (collapsed) Gibbs sampling\n",
            "Iteration 1380 of (collapsed) Gibbs sampling\n",
            "Iteration 1390 of (collapsed) Gibbs sampling\n",
            "Iteration 1400 of (collapsed) Gibbs sampling\n",
            "Iteration 1410 of (collapsed) Gibbs sampling\n",
            "Iteration 1420 of (collapsed) Gibbs sampling\n",
            "Iteration 1430 of (collapsed) Gibbs sampling\n",
            "Iteration 1440 of (collapsed) Gibbs sampling\n",
            "Iteration 1450 of (collapsed) Gibbs sampling\n",
            "Iteration 1460 of (collapsed) Gibbs sampling\n",
            "Iteration 1470 of (collapsed) Gibbs sampling\n",
            "Iteration 1480 of (collapsed) Gibbs sampling\n",
            "Iteration 1490 of (collapsed) Gibbs sampling\n",
            "Iteration 1500 of (collapsed) Gibbs sampling\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1006.82375134,  963.73255146,  948.38402457,  942.2702906 ,\n",
              "        938.53840376,  935.13687021,  934.53396167,  932.92667881,\n",
              "        932.85765188,  932.57659017,  931.63871787,  931.70091363,\n",
              "        932.03052927,  931.71449623,  930.8235753 ,  930.99404018,\n",
              "        931.62609147,  931.80610869,  931.2675133 ,  929.68505135,\n",
              "        930.65877233,  932.00703588,  930.35281107,  931.3202266 ,\n",
              "        929.90844595,  929.60829835,  930.05441232,  930.89523435,\n",
              "        929.28328669,  930.05594095])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here it would be preferable to use a convergence criterion to decide when to stop the sampling based on a minimized perplexity, for example stopping when the perplexity does not improve by more than 10^-2.\n",
        "\n",
        "However, this would require a lot of computational power. I only have time limited use of GPU on Colab, therefore I opted for not using a convergence criterion for the purpose of this assignment."
      ],
      "metadata": {
        "id": "UnNwhBdeY6zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping the last n samples (as they are the ones with the lowest perplexity, n is arbitrary)\n",
        "n = 10\n",
        "ldaobj.samples_keep(n)"
      ],
      "metadata": {
        "id": "n9E3z2BDYoZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One should normally take as many samples as computationally feasible but given my low computational power, I choose $n$ arbitrarily to be small."
      ],
      "metadata": {
        "id": "mXCrtVG5mhXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us look at the shape:\n",
        "    # of my estimated topics\n",
        "print(ldaobj.tt.shape)\n",
        "# All good, it matches my number of unique stems, topics, and samples\n",
        "    # of my estimated document-topic distributions\n",
        "print(ldaobj.dt.shape)\n",
        "# All good, it matches my number of documents, topics, and samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm0XEp2sZc7m",
        "outputId": "fd3c91e0-349f-4278-96c7-e1ea110a2e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4918, 20, 10)\n",
            "(10260, 20, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I will extract a csv file containing the first m stems in each topic ranked according to their probability, using the final stored sample\n",
        "m = 20 # chosen arbitrarily \n",
        "ldaobj.topic_content(m)"
      ],
      "metadata": {
        "id": "bwS5r0hyaUjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have checked the topics and they seem reasonable."
      ],
      "metadata": {
        "id": "_D3uA9xOahax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Ranking topics according to whether they are more Democrat or Republican"
      ],
      "metadata": {
        "id": "nh0R6TnjLxy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I use querying to bring the analysis from paragraph level to speech level (one speech per year), obtaining speech level distributions."
      ],
      "metadata": {
        "id": "fpQJlmWnpOMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimated distribution of the m topics (m columns) within each document (each row)\n",
        "dt = ldaobj.dt_avg() # suming each row = 1\n",
        "\n",
        "## This gives in each cell the proportion that a topic represents in each document"
      ],
      "metadata": {
        "id": "hXxGyoPGQlWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimated distribution of the m topics (m columns) within each stems (each row)\n",
        "tt = ldaobj.tt_avg() # suming each column = 1\n",
        "ldaobj.dict_print()\n",
        "\n",
        "## This gives in each cell the associative power of a stem to a given topic"
      ],
      "metadata": {
        "id": "Lt7_uS8QRW0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building my final dataset at speech level\n",
        "data['speech'] = [' '.join(s) for s in docsobj.stems] # I replace the speech field in the original data with its cleaned version from docsobj (after the processing done previously)\n",
        "aggspeeches = data.groupby(['year','president'])['speech'].apply(lambda x: ' '.join(x)) # I aggregate up to the speech level\n",
        "aggdocs = topicmodels.RawDocs(aggspeeches) # create new RawDocs object that contains entire speech stems in aggdocs.tokens\n",
        "queryobj = topicmodels.LDA.QueryGibbs(aggdocs.tokens,ldaobj.token_key,ldaobj.tt) # initialize query object with ldaobj attributes\n",
        "queryobj.query(10) # I query the selected samples (querying does not require a lot of iterations to obtain good perplexity, so 10 is chosen arbitrarily)\n",
        "dt_query = queryobj.dt_avg()\n",
        "aggdata = pd.DataFrame(dt_query,index=aggspeeches.index,columns=['T' + str(i) for i in range(queryobj.K)]) # Aggregating\n",
        "aggdata.to_csv(\"final_output_agg.csv\") # Obtaining final dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWp26iNWWmq_",
        "outputId": "3c83d3c3-306d-41cb-8ebd-f740aad059ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0 queried\n",
            "Sample 1 queried\n",
            "Sample 2 queried\n",
            "Sample 3 queried\n",
            "Sample 4 queried\n",
            "Sample 5 queried\n",
            "Sample 6 queried\n",
            "Sample 7 queried\n",
            "Sample 8 queried\n",
            "Sample 9 queried\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I now have in \"final_output_agg.cv\" a row per speech and a column per topic. For each speech the row sums to 1 across all topics.\n"
      ],
      "metadata": {
        "id": "95Enmfl-ZNh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I use the csv file created\n",
        "final_data = pd.read_csv(\"final_output_agg.csv\")\n",
        "final_data # Checking the data"
      ],
      "metadata": {
        "id": "3siDecqRa85L",
        "outputId": "2f5712d7-f04b-4353-c668-93a2d3f5fc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year    president        T0        T1        T2        T3        T4  \\\n",
              "0   1945  RooseveltII  0.025638  0.038671  0.044399  0.025930  0.049347   \n",
              "1   1946       Truman  0.029688  0.046944  0.027567  0.063902  0.027819   \n",
              "2   1947       Truman  0.025448  0.060696  0.029300  0.065934  0.036938   \n",
              "3   1948       Truman  0.054406  0.058973  0.052910  0.039935  0.046928   \n",
              "4   1949       Truman  0.055107  0.044774  0.042221  0.053800  0.060926   \n",
              "..   ...          ...       ...       ...       ...       ...       ...   \n",
              "68  2010        Obama  0.029365  0.024028  0.055830  0.036706  0.054719   \n",
              "69  2011        Obama  0.060125  0.012710  0.071880  0.036319  0.045901   \n",
              "70  2012        Obama  0.061505  0.012295  0.057138  0.036884  0.063673   \n",
              "71  2013        Obama  0.045778  0.020785  0.053319  0.028981  0.065784   \n",
              "72  2014        Obama  0.038181  0.014694  0.059922  0.026528  0.044294   \n",
              "\n",
              "          T5        T6        T7  ...       T10       T11       T12       T13  \\\n",
              "0   0.059790  0.017358  0.057335  ...  0.029476  0.051354  0.046678  0.022462   \n",
              "1   0.026469  0.166142  0.019303  ...  0.074043  0.010720  0.093947  0.070304   \n",
              "2   0.044610  0.035891  0.043258  ...  0.091957  0.016560  0.072626  0.053498   \n",
              "3   0.089410  0.053072  0.020614  ...  0.064551  0.025546  0.096281  0.044826   \n",
              "4   0.077494  0.024762  0.012411  ...  0.095071  0.026069  0.086520  0.054394   \n",
              "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "68  0.047903  0.066194  0.045250  ...  0.056848  0.078408  0.038279  0.022856   \n",
              "69  0.032236  0.054890  0.044024  ...  0.046855  0.098222  0.023148  0.017221   \n",
              "70  0.041530  0.069186  0.046826  ...  0.048405  0.080830  0.033788  0.020780   \n",
              "71  0.047834  0.059271  0.054815  ...  0.029355  0.066500  0.044718  0.022998   \n",
              "72  0.044083  0.039295  0.066576  ...  0.045498  0.091298  0.044113  0.019904   \n",
              "\n",
              "         T14       T15       T16       T17       T18       T19  \n",
              "0   0.145061  0.057549  0.124196  0.023164  0.095130  0.037541  \n",
              "1   0.067099  0.054651  0.056617  0.053865  0.037982  0.048346  \n",
              "2   0.072051  0.072829  0.071747  0.072998  0.041230  0.047854  \n",
              "3   0.065481  0.070857  0.039491  0.018674  0.056265  0.058327  \n",
              "4   0.051069  0.047743  0.045606  0.047268  0.044299  0.069121  \n",
              "..       ...       ...       ...       ...       ...       ...  \n",
              "68  0.060919  0.030321  0.014528  0.021777  0.023597  0.058174  \n",
              "69  0.053309  0.042542  0.014554  0.015772  0.031709  0.044880  \n",
              "70  0.049768  0.030567  0.016104  0.024559  0.028182  0.035026  \n",
              "71  0.036242  0.035525  0.025584  0.027298  0.027174  0.048582  \n",
              "72  0.035923  0.036314  0.029027  0.018729  0.028245  0.047094  \n",
              "\n",
              "[73 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b1a1dde-a98f-47d2-81e0-a9199252ec18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>president</th>\n",
              "      <th>T0</th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>T3</th>\n",
              "      <th>T4</th>\n",
              "      <th>T5</th>\n",
              "      <th>T6</th>\n",
              "      <th>T7</th>\n",
              "      <th>...</th>\n",
              "      <th>T10</th>\n",
              "      <th>T11</th>\n",
              "      <th>T12</th>\n",
              "      <th>T13</th>\n",
              "      <th>T14</th>\n",
              "      <th>T15</th>\n",
              "      <th>T16</th>\n",
              "      <th>T17</th>\n",
              "      <th>T18</th>\n",
              "      <th>T19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1945</td>\n",
              "      <td>RooseveltII</td>\n",
              "      <td>0.025638</td>\n",
              "      <td>0.038671</td>\n",
              "      <td>0.044399</td>\n",
              "      <td>0.025930</td>\n",
              "      <td>0.049347</td>\n",
              "      <td>0.059790</td>\n",
              "      <td>0.017358</td>\n",
              "      <td>0.057335</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029476</td>\n",
              "      <td>0.051354</td>\n",
              "      <td>0.046678</td>\n",
              "      <td>0.022462</td>\n",
              "      <td>0.145061</td>\n",
              "      <td>0.057549</td>\n",
              "      <td>0.124196</td>\n",
              "      <td>0.023164</td>\n",
              "      <td>0.095130</td>\n",
              "      <td>0.037541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1946</td>\n",
              "      <td>Truman</td>\n",
              "      <td>0.029688</td>\n",
              "      <td>0.046944</td>\n",
              "      <td>0.027567</td>\n",
              "      <td>0.063902</td>\n",
              "      <td>0.027819</td>\n",
              "      <td>0.026469</td>\n",
              "      <td>0.166142</td>\n",
              "      <td>0.019303</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074043</td>\n",
              "      <td>0.010720</td>\n",
              "      <td>0.093947</td>\n",
              "      <td>0.070304</td>\n",
              "      <td>0.067099</td>\n",
              "      <td>0.054651</td>\n",
              "      <td>0.056617</td>\n",
              "      <td>0.053865</td>\n",
              "      <td>0.037982</td>\n",
              "      <td>0.048346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1947</td>\n",
              "      <td>Truman</td>\n",
              "      <td>0.025448</td>\n",
              "      <td>0.060696</td>\n",
              "      <td>0.029300</td>\n",
              "      <td>0.065934</td>\n",
              "      <td>0.036938</td>\n",
              "      <td>0.044610</td>\n",
              "      <td>0.035891</td>\n",
              "      <td>0.043258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091957</td>\n",
              "      <td>0.016560</td>\n",
              "      <td>0.072626</td>\n",
              "      <td>0.053498</td>\n",
              "      <td>0.072051</td>\n",
              "      <td>0.072829</td>\n",
              "      <td>0.071747</td>\n",
              "      <td>0.072998</td>\n",
              "      <td>0.041230</td>\n",
              "      <td>0.047854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1948</td>\n",
              "      <td>Truman</td>\n",
              "      <td>0.054406</td>\n",
              "      <td>0.058973</td>\n",
              "      <td>0.052910</td>\n",
              "      <td>0.039935</td>\n",
              "      <td>0.046928</td>\n",
              "      <td>0.089410</td>\n",
              "      <td>0.053072</td>\n",
              "      <td>0.020614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064551</td>\n",
              "      <td>0.025546</td>\n",
              "      <td>0.096281</td>\n",
              "      <td>0.044826</td>\n",
              "      <td>0.065481</td>\n",
              "      <td>0.070857</td>\n",
              "      <td>0.039491</td>\n",
              "      <td>0.018674</td>\n",
              "      <td>0.056265</td>\n",
              "      <td>0.058327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949</td>\n",
              "      <td>Truman</td>\n",
              "      <td>0.055107</td>\n",
              "      <td>0.044774</td>\n",
              "      <td>0.042221</td>\n",
              "      <td>0.053800</td>\n",
              "      <td>0.060926</td>\n",
              "      <td>0.077494</td>\n",
              "      <td>0.024762</td>\n",
              "      <td>0.012411</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095071</td>\n",
              "      <td>0.026069</td>\n",
              "      <td>0.086520</td>\n",
              "      <td>0.054394</td>\n",
              "      <td>0.051069</td>\n",
              "      <td>0.047743</td>\n",
              "      <td>0.045606</td>\n",
              "      <td>0.047268</td>\n",
              "      <td>0.044299</td>\n",
              "      <td>0.069121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>2010</td>\n",
              "      <td>Obama</td>\n",
              "      <td>0.029365</td>\n",
              "      <td>0.024028</td>\n",
              "      <td>0.055830</td>\n",
              "      <td>0.036706</td>\n",
              "      <td>0.054719</td>\n",
              "      <td>0.047903</td>\n",
              "      <td>0.066194</td>\n",
              "      <td>0.045250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056848</td>\n",
              "      <td>0.078408</td>\n",
              "      <td>0.038279</td>\n",
              "      <td>0.022856</td>\n",
              "      <td>0.060919</td>\n",
              "      <td>0.030321</td>\n",
              "      <td>0.014528</td>\n",
              "      <td>0.021777</td>\n",
              "      <td>0.023597</td>\n",
              "      <td>0.058174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2011</td>\n",
              "      <td>Obama</td>\n",
              "      <td>0.060125</td>\n",
              "      <td>0.012710</td>\n",
              "      <td>0.071880</td>\n",
              "      <td>0.036319</td>\n",
              "      <td>0.045901</td>\n",
              "      <td>0.032236</td>\n",
              "      <td>0.054890</td>\n",
              "      <td>0.044024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046855</td>\n",
              "      <td>0.098222</td>\n",
              "      <td>0.023148</td>\n",
              "      <td>0.017221</td>\n",
              "      <td>0.053309</td>\n",
              "      <td>0.042542</td>\n",
              "      <td>0.014554</td>\n",
              "      <td>0.015772</td>\n",
              "      <td>0.031709</td>\n",
              "      <td>0.044880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>2012</td>\n",
              "      <td>Obama</td>\n",
              "      <td>0.061505</td>\n",
              "      <td>0.012295</td>\n",
              "      <td>0.057138</td>\n",
              "      <td>0.036884</td>\n",
              "      <td>0.063673</td>\n",
              "      <td>0.041530</td>\n",
              "      <td>0.069186</td>\n",
              "      <td>0.046826</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048405</td>\n",
              "      <td>0.080830</td>\n",
              "      <td>0.033788</td>\n",
              "      <td>0.020780</td>\n",
              "      <td>0.049768</td>\n",
              "      <td>0.030567</td>\n",
              "      <td>0.016104</td>\n",
              "      <td>0.024559</td>\n",
              "      <td>0.028182</td>\n",
              "      <td>0.035026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2013</td>\n",
              "      <td>Obama</td>\n",
              "      <td>0.045778</td>\n",
              "      <td>0.020785</td>\n",
              "      <td>0.053319</td>\n",
              "      <td>0.028981</td>\n",
              "      <td>0.065784</td>\n",
              "      <td>0.047834</td>\n",
              "      <td>0.059271</td>\n",
              "      <td>0.054815</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029355</td>\n",
              "      <td>0.066500</td>\n",
              "      <td>0.044718</td>\n",
              "      <td>0.022998</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.035525</td>\n",
              "      <td>0.025584</td>\n",
              "      <td>0.027298</td>\n",
              "      <td>0.027174</td>\n",
              "      <td>0.048582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>2014</td>\n",
              "      <td>Obama</td>\n",
              "      <td>0.038181</td>\n",
              "      <td>0.014694</td>\n",
              "      <td>0.059922</td>\n",
              "      <td>0.026528</td>\n",
              "      <td>0.044294</td>\n",
              "      <td>0.044083</td>\n",
              "      <td>0.039295</td>\n",
              "      <td>0.066576</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045498</td>\n",
              "      <td>0.091298</td>\n",
              "      <td>0.044113</td>\n",
              "      <td>0.019904</td>\n",
              "      <td>0.035923</td>\n",
              "      <td>0.036314</td>\n",
              "      <td>0.029027</td>\n",
              "      <td>0.018729</td>\n",
              "      <td>0.028245</td>\n",
              "      <td>0.047094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73 rows  22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b1a1dde-a98f-47d2-81e0-a9199252ec18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b1a1dde-a98f-47d2-81e0-a9199252ec18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b1a1dde-a98f-47d2-81e0-a9199252ec18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use the respective partisanship of each president in the sample: Truman (D), Eisenhower (R), Kennedy (D), Johnson (D), Nixon (R), Ford (R), Carter (D), Reagan (R), Bush Senior (R), Clinton (D), Bush Jr (R), and Obama (D). \n",
        "\n",
        "I create a dummy for being Republican (=1) or not (=0). Calculating the correlation between this dummy and the topics allows me to rank topics as either Democrat (if the correlation is negative) or Republican (if the correlation is positive). I also obtain a scale from -1 (most Democrat) to 1 (most Republican) on which I can rank each topic according to the obtained correlations.\n",
        "\n",
        "To note: I can proceed this way as the sample is well balanced with 50.7% of speeches coming from Republican presidents and 49.3% from Democrat presidents."
      ],
      "metadata": {
        "id": "p0AWB5hbL-zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dummy Rep (=1 for Republicans, = 0 for Democrats)\n",
        "final_data[\"rep\"] = 0\n",
        "republicans = [\"Eisenhower\", \"Nixon\", \"Ford\", \"Reagan\", \"BushI\", \"BushII\"] # using information given in the instructions\n",
        "final_data[\"rep\"] = final_data.apply(\n",
        "    lambda x: 1 if x[\"president\"] in republicans else 0, axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "Ttg2Jbe0i9af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the correlation of each topic with the speaker being Republican\n",
        "topics = final_data.columns[2:-1]\n",
        "topics_correlations = pd.DataFrame(topics, columns=[\"topics\"])\n",
        "topics_correlations[\"corr\"] = 0\n",
        "for topic in topics_correlations.topics.unique(): \n",
        "  topics_correlations.loc[topics_correlations[\"topics\"]==topic, \"corr\"] = final_data[[topic,\"rep\"]].corr().iloc[0,1]"
      ],
      "metadata": {
        "id": "4y7cPL1Jkjbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordering the topics from the most Democrat (most negative) to the most Republican (most positive)\n",
        "topics_correlations_no = topics_correlations.sort_values(by=[\"corr\"]).reset_index(drop=True) # ordered ascending\n",
        "topics_correlations_no"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "c5xymdMQpKVa",
        "outputId": "6b28ce3f-e442-4aad-a967-f67ee79c177b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   topics      corr\n",
              "0      T8 -0.290251\n",
              "1     T10 -0.208209\n",
              "2     T14 -0.207259\n",
              "3      T4 -0.144576\n",
              "4     T19 -0.133791\n",
              "5     T18 -0.130346\n",
              "6      T9 -0.128651\n",
              "7     T12 -0.085157\n",
              "8     T13 -0.015089\n",
              "9     T17 -0.004999\n",
              "10    T15  0.042160\n",
              "11     T6  0.066594\n",
              "12     T2  0.077378\n",
              "13    T16  0.082061\n",
              "14     T0  0.109692\n",
              "15     T1  0.153619\n",
              "16     T5  0.163031\n",
              "17     T7  0.191731\n",
              "18    T11  0.214443\n",
              "19     T3  0.348831"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1394be6-f3c1-43d7-b232-eb6d650c2fc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topics</th>\n",
              "      <th>corr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T8</td>\n",
              "      <td>-0.290251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T10</td>\n",
              "      <td>-0.208209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T14</td>\n",
              "      <td>-0.207259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T4</td>\n",
              "      <td>-0.144576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T19</td>\n",
              "      <td>-0.133791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>T18</td>\n",
              "      <td>-0.130346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>T9</td>\n",
              "      <td>-0.128651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>T12</td>\n",
              "      <td>-0.085157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>T13</td>\n",
              "      <td>-0.015089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>T17</td>\n",
              "      <td>-0.004999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>T15</td>\n",
              "      <td>0.042160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>T6</td>\n",
              "      <td>0.066594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>T2</td>\n",
              "      <td>0.077378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>T16</td>\n",
              "      <td>0.082061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>T0</td>\n",
              "      <td>0.109692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>T1</td>\n",
              "      <td>0.153619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>T5</td>\n",
              "      <td>0.163031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>T7</td>\n",
              "      <td>0.191731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>T11</td>\n",
              "      <td>0.214443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>T3</td>\n",
              "      <td>0.348831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1394be6-f3c1-43d7-b232-eb6d650c2fc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1394be6-f3c1-43d7-b232-eb6d650c2fc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1394be6-f3c1-43d7-b232-eb6d650c2fc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, I obtain a ranking of topics from most Democrat (most negative correlation) to most Republican (most positive correlation)."
      ],
      "metadata": {
        "id": "hg2RhqJu9TqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ranking presidents on the basis of D-R scale"
      ],
      "metadata": {
        "id": "CNcu1vInN38w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I weight negatively Democrat topics for Republican presidents and vice versa for Democrat presidents. Then, I sum across the weighted topics for each speech. I then average the score for each president across all their respective speeches."
      ],
      "metadata": {
        "id": "bUQ9R6WI_h8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dummy to assign each topic to be either Republican (with a positive correlation) or Democrat (with a negative correlation)\n",
        "topics_correlations[\"topic_ideology\"] = topics_correlations[\"corr\"].copy()\n",
        "topics_correlations[\"topic_ideology\"] = topics_correlations[\"topic_ideology\"].apply(\n",
        "    lambda x: -1 if x < 0 else 1\n",
        ")"
      ],
      "metadata": {
        "id": "j3Y57eO7ouxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_ideology_r=topics_correlations[\"topic_ideology\"].values\n",
        "topic_ideology_r"
      ],
      "metadata": {
        "id": "NZ-yr2IkR4dw",
        "outputId": "d778c59a-58aa-4278-99ba-acb2771894cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1,  1,\n",
              "       -1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grading each speech from most Democrat (most negative) to most Republican (most positive)\n",
        "df = final_data[[\"year\",\"president\"]].drop_duplicates()\n",
        "df[\"grade\"] = 0\n",
        "\n",
        "for index, row in final_data.iterrows():\n",
        "  t = np.array(row[topics].values)\n",
        "  if row[\"rep\"] == 1:\n",
        "    j = 1 \n",
        "  else:\n",
        "    j = -1 \n",
        "    # I 'penalize' Democrats for using Republican topics and vice versa\n",
        "  grade = (topic_ideology_r*j).T@t*j\n",
        "  df.iloc[index,2] = grade"
      ],
      "metadata": {
        "id": "aIQxNdIIsKM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1LgEJhTDJ-z6",
        "outputId": "a7e3b535-b9cf-4505-b5bf-82066ab520f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year    president     grade\n",
              "0   1945  RooseveltII  0.004442\n",
              "1   1946       Truman  0.004006\n",
              "2   1947       Truman -0.067455\n",
              "3   1948       Truman  0.010428\n",
              "4   1949       Truman -0.140024\n",
              "..   ...          ...       ...\n",
              "68  2010        Obama -0.142936\n",
              "69  2011        Obama -0.064998\n",
              "70  2012        Obama -0.094271\n",
              "71  2013        Obama -0.123216\n",
              "72  2014        Obama -0.108160\n",
              "\n",
              "[73 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fd7cd55-0c61-415b-8478-0c8a7ae50d7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>president</th>\n",
              "      <th>grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1945</td>\n",
              "      <td>RooseveltII</td>\n",
              "      <td>0.004442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1946</td>\n",
              "      <td>Truman</td>\n",
              "      <td>0.004006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1947</td>\n",
              "      <td>Truman</td>\n",
              "      <td>-0.067455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1948</td>\n",
              "      <td>Truman</td>\n",
              "      <td>0.010428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949</td>\n",
              "      <td>Truman</td>\n",
              "      <td>-0.140024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>2010</td>\n",
              "      <td>Obama</td>\n",
              "      <td>-0.142936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2011</td>\n",
              "      <td>Obama</td>\n",
              "      <td>-0.064998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>2012</td>\n",
              "      <td>Obama</td>\n",
              "      <td>-0.094271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2013</td>\n",
              "      <td>Obama</td>\n",
              "      <td>-0.123216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>2014</td>\n",
              "      <td>Obama</td>\n",
              "      <td>-0.108160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fd7cd55-0c61-415b-8478-0c8a7ae50d7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fd7cd55-0c61-415b-8478-0c8a7ae50d7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fd7cd55-0c61-415b-8478-0c8a7ae50d7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Averaging grades and collapsing at president level\n",
        "df_collapse = df.pivot_table(values=[\"grade\"], index=[\"president\"], aggfunc=\"mean\").reset_index()\n",
        "df_collapse = df_collapse.sort_values(by=[\"grade\"]).reset_index(drop=True)\n",
        "df_collapse # Show the ranking (ascending order)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "0zVtQ1Xy_Wy3",
        "outputId": "1dabf1e1-eadf-4c06-9a3f-339d409afc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      president     grade\n",
              "0       Clinton -0.169693\n",
              "1         Obama -0.107369\n",
              "2       Kennedy -0.057293\n",
              "3     JohnsonII -0.040971\n",
              "4        Carter -0.036964\n",
              "5        Truman -0.031356\n",
              "6         BushI -0.026077\n",
              "7   RooseveltII  0.004442\n",
              "8        Reagan  0.032494\n",
              "9    Eisenhower  0.078144\n",
              "10       BushII  0.090275\n",
              "11         Ford  0.103686\n",
              "12        Nixon  0.108421"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bf4783f-66d5-492c-ac7d-b9475b7bd3f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>president</th>\n",
              "      <th>grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Clinton</td>\n",
              "      <td>-0.169693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Obama</td>\n",
              "      <td>-0.107369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kennedy</td>\n",
              "      <td>-0.057293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JohnsonII</td>\n",
              "      <td>-0.040971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Carter</td>\n",
              "      <td>-0.036964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Truman</td>\n",
              "      <td>-0.031356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BushI</td>\n",
              "      <td>-0.026077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RooseveltII</td>\n",
              "      <td>0.004442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Reagan</td>\n",
              "      <td>0.032494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Eisenhower</td>\n",
              "      <td>0.078144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BushII</td>\n",
              "      <td>0.090275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Ford</td>\n",
              "      <td>0.103686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Nixon</td>\n",
              "      <td>0.108421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bf4783f-66d5-492c-ac7d-b9475b7bd3f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bf4783f-66d5-492c-ac7d-b9475b7bd3f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bf4783f-66d5-492c-ac7d-b9475b7bd3f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting to get a sense of the relative ranking between presidents as the relative differences in grades are not constant\n",
        "df_collapse.plot(x=\"president\",y=\"grade\",kind=\"scatter\", figsize=(12,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "hSMoNu9i42RI",
        "outputId": "45ebbb50-c810-4ddd-c2b4-0cb8f0e28c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3955e54810>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, I obtain a ranking of presidents from most Democrat (most negative correlation) to most Republican (most positive correlation).\n",
        "\n",
        "The actual grades are not meaningful, but the relative differences between presidents and the ranking sorted in ascending order (from least to most Republican) are meaningful and relevant."
      ],
      "metadata": {
        "id": "4HmjPOxVBG0H"
      }
    }
  ]
}