{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLr5yxjLRzKRyMWlJW62g5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mearoche/text-mining-tutorial/blob/master/Ass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Data import and preparation/clean up"
      ],
      "metadata": {
        "id": "LyNS9SNOZa6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up"
      ],
      "metadata": {
        "id": "_Gk76RJ1Zf7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Colab: \n",
        "# 1. First CHANGE RUNTIME TYPE to GPU \n",
        "# 2. Then run install commands commented out below\n",
        "# 3. Then RESTART RUNTIME\n",
        "# 4. Then run git clone command commented out below\n",
        "# 5. Then run all the other cells"
      ],
      "metadata": {
        "id": "cBgkhw8FZjlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install --upgrade jax==0.2.3 jaxlib==0.1.56+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "!pip install --upgrade numpyro==0.4.1\n",
        "!pip install flashtext\n",
        "!pip install contractions\n",
        "!pip install lda\n",
        "!pip install --upgrade spacy==2.2.4\n",
        "!pip install --upgrade folium==0.2.1\n",
        "!pip install topic-modelling-tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7LmlVB9Zlyo",
        "outputId": "144272da-989c-48f4-93fd-421ac48767a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_releases.html\n",
            "Requirement already satisfied: jax==0.2.3 in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: jaxlib==0.1.56+cuda110 in /usr/local/lib/python3.7/dist-packages (0.1.56+cuda110)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.3) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.3) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.3) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.56+cuda110) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: numpyro==0.4.1 in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: jaxlib==0.1.56 in /usr/local/lib/python3.7/dist-packages (from numpyro==0.4.1) (0.1.56+cuda110)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from numpyro==0.4.1) (4.63.0)\n",
            "Requirement already satisfied: jax==0.2.3 in /usr/local/lib/python3.7/dist-packages (from numpyro==0.4.1) (0.2.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.3->numpyro==0.4.1) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.3->numpyro==0.4.1) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.3->numpyro==0.4.1) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.56->numpyro==0.4.1) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax==0.2.3->numpyro==0.4.1) (1.15.0)\n",
            "Requirement already satisfied: flashtext in /usr/local/lib/python3.7/dist-packages (2.7)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.68)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: lda in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from lda) (1.19.5)\n",
            "Requirement already satisfied: pbr<4,>=0.6 in /usr/local/lib/python3.7/dist-packages (from lda) (3.1.1)\n",
            "Requirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (3.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (4.63.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2021.10.8)\n",
            "Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Collecting topic-modelling-tools\n",
            "  Downloading topic-modelling-tools-0.7.dev0.tar.gz (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from topic-modelling-tools) (1.19.5)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.7/dist-packages (from topic-modelling-tools) (3.2.5)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from topic-modelling-tools) (1.3.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from topic-modelling-tools) (1.4.1)\n",
            "Requirement already satisfied: Cython>=0.20.1 in /usr/local/lib/python3.7/dist-packages (from topic-modelling-tools) (0.29.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.4->topic-modelling-tools) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->topic-modelling-tools) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->topic-modelling-tools) (2.8.2)\n",
            "Building wheels for collected packages: topic-modelling-tools\n",
            "  Building wheel for topic-modelling-tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for topic-modelling-tools: filename=topic_modelling_tools-0.7.dev0-cp37-cp37m-linux_x86_64.whl size=329226 sha256=9490232d160ec2a4c0e9d0a5fb78c84edc5efff8a497a1cf0356db8f1afa237b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/d0/ee/e1a1f534a2794a356b473a713dc6905463aed85025499c6c2d\n",
            "Successfully built topic-modelling-tools\n",
            "Installing collected packages: topic-modelling-tools\n",
            "Successfully installed topic-modelling-tools-0.7.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart RUNTIME after installing packages!"
      ],
      "metadata": {
        "id": "PWo9ez2BZplT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning GitHub (to do only once! Then comment it)\n",
        "!git clone https://mearoche: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@github.com/mearoche/text-mining-tutorial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3NVMfWCZqQR",
        "outputId": "60b56564-ed98-4303-939c-a8de261b0458"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-mining-tutorial'...\n",
            "remote: Enumerating objects: 692, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 692 (delta 4), reused 0 (delta 0), pack-reused 683\u001b[K\n",
            "Receiving objects: 100% (692/692), 13.86 MiB | 17.90 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd text-mining-tutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhB6r4lsZrvn",
        "outputId": "dcef0a5c-5389-44da-8405-2d5db3cb42d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-mining-tutorial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the directory contains the growthdata.csv file\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7VgcRs-ZusU",
        "outputId": "930076e1-c736-45af-de7d-343b034c066f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ass3.ipynb  requirements.txt\t    tutorial_notebook.ipynb\n",
            "README.md   speech_data_extend.txt  tutorial.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "\n",
        "# JAX\n",
        "import jax\n",
        "from jax import random, vmap, jit\n",
        "import jax.numpy as jnp\n",
        "import jax.nn as nn\n",
        "from jax.random import PRNGKey as Key\n",
        "\n",
        "# Panda\n",
        "import pandas as pd\n",
        "\n",
        "# Numpyro\n",
        "import numpyro\n",
        "numpyro.set_platform(\"cpu\")\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS, log_likelihood\n",
        "import numpyro.infer.util \n",
        "from numpyro.primitives import deterministic\n",
        "from numpyro.handlers import condition, substitute, block\n",
        "\n",
        "# Matplot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Spacy\n",
        "import spacy\n",
        "spacy.load('en_core_web_sm')\n",
        "\n",
        "# LDA\n",
        "import lda\n",
        "\n",
        "# Others\n",
        "import time\n",
        "import string\n",
        "import topicmodels\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sys\n",
        "sys.path.append('../pymodules')"
      ],
      "metadata": {
        "id": "ivVCF7D3ZxdI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import data"
      ],
      "metadata": {
        "id": "7HS0EAxyaTZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import US Presidential State-of-the-Union addresses from 1945 onwards\n",
        "data = pd.read_table(\"speech_data_extend.txt\", encoding=\"utf-8\")\n",
        "data.columns\n",
        "data = data[data.year >= 1945]"
      ],
      "metadata": {
        "id": "2P4UpG0taVEN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of documents in the dataset\n",
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcEcHHzogfxj",
        "outputId": "dba0cbb0-aa6e-40fc-ad96-1c6d7bafb3c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10260"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. LDA"
      ],
      "metadata": {
        "id": "yPXDOkhLjWz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing"
      ],
      "metadata": {
        "id": "1awPe-dbjYqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I define docsobj, tokenized\n",
        "docsobj = topicmodels.RawDocs(data.speech, \"long\")"
      ],
      "metadata": {
        "id": "b_G48Ep9ja6-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the stop words list\n",
        "docsobj.stopwords"
      ],
      "metadata": {
        "id": "0VzS5gFsnafO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee34c6a-9a0d-49ec-8116-0c3feb8e2449"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'also',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'are',\n",
              " 'as',\n",
              " 'at',\n",
              " 'back',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'could',\n",
              " 'did',\n",
              " 'do',\n",
              " 'does',\n",
              " 'doing',\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'few',\n",
              " 'first',\n",
              " 'five',\n",
              " 'for',\n",
              " 'four',\n",
              " 'from',\n",
              " 'further',\n",
              " 'get',\n",
              " 'go',\n",
              " 'goes',\n",
              " 'had',\n",
              " 'has',\n",
              " 'have',\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'high',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'however',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'least',\n",
              " 'less',\n",
              " 'like',\n",
              " 'long',\n",
              " 'made',\n",
              " 'make',\n",
              " 'many',\n",
              " 'me',\n",
              " 'more',\n",
              " 'most',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'never',\n",
              " 'new',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'of',\n",
              " 'off',\n",
              " 'old',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'ought',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'put',\n",
              " 'said',\n",
              " 'same',\n",
              " 'say',\n",
              " 'says',\n",
              " 'second',\n",
              " 'see',\n",
              " 'seen',\n",
              " 'she',\n",
              " 'should',\n",
              " 'since',\n",
              " 'so',\n",
              " 'some',\n",
              " 'still',\n",
              " 'such',\n",
              " 'take',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'three',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'two',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'us',\n",
              " 'very',\n",
              " 'was',\n",
              " 'way',\n",
              " 'we',\n",
              " 'well',\n",
              " 'were',\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'with',\n",
              " 'would',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we want to focus on words and not tokens, I will clean the tokens (clean all non-alphabetic and numeric tokens), and remove with length less than 1\n",
        "docsobj.token_clean(1)"
      ],
      "metadata": {
        "id": "nSzOw-AQnxRk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I remove the stopwords\n",
        "docsobj.stopword_remove(\"tokens\")"
      ],
      "metadata": {
        "id": "5FISLTBtoYVX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to group together words that are grammatically different but thematically identical, i.e. stemming, using Porter stemmer\n",
        "docsobj.stem()\n",
        "docsobj.stopword_remove(\"stems\") # I again remove stopwords as stemmed forms of tokens may be in the stoword list"
      ],
      "metadata": {
        "id": "qsBln3ewonUR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of TF-IDF on each stem to measure informativeness (to identify common words and rare words)\n",
        "docsobj.term_rank(\"stems\") # Outcome is 2 csv files, df_ranking.csv ranks each stem according to its document frequency, and tfidf_ranking.csv ranks each stem accroding to the tf-idf measure."
      ],
      "metadata": {
        "id": "D1d55d8mpI7F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the ranking of the TF-IDF\n",
        "plt.plot([x[1] for x in docsobj.tfidf_ranking])"
      ],
      "metadata": {
        "id": "MYC_lqaEpvPj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1cf15f36-457b-4871-bd41-f1933e0679f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9301de6d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I take as cutoff 5,000 as it seems reasonable according to the above plot"
      ],
      "metadata": {
        "id": "7mAEIPF8qkyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I now drop the stems below this cutoff\n",
        "cutoff = 5000\n",
        "docsobj.rank_remove(\"tfidf\",\"stems\",docsobj.tfidf_ranking[cutoff][1])\n",
        "all_stems = [s for d in docsobj.stems for s in d]"
      ],
      "metadata": {
        "id": "nqh6Fyauqryp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of unique stems\n",
        "print(len(set(all_stems)))\n",
        "V = len(set(all_stems))\n",
        "# Check number of total stems\n",
        "print(len(all_stems))"
      ],
      "metadata": {
        "id": "Fm9QMEbarCSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885f2d4c-7122-4406-b153-cc3a030270c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4918\n",
            "268763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, I obtain 4,918 unique stems and 268,763 total stems. I can now estimate my LDA."
      ],
      "metadata": {
        "id": "6o0cXUKmrO0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estimations"
      ],
      "metadata": {
        "id": "xF8hrugGpNUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will estimate an LDA on individual paragraphs using the collapsed Gibbs sampling algorithm of Griffiths and Steyvers (2004)."
      ],
      "metadata": {
        "id": "L3QakVDVUQXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the number of topics\n",
        "topics = 20\n",
        "ldaobj = topicmodels.LDA.LDAGibbs(docsobj.stems,topics)"
      ],
      "metadata": {
        "id": "03LSAanpUaqa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the hyperparameters of the Dirichlet priors, here I follow Griffiths and Steyvers (2004)\n",
        "print(ldaobj.K) # number of topic, user defined, here topics = K = 20\n",
        "print(ldaobj.alpha) # hyperparameter for document-topic distribution, automatically defined as 50/K, with K the number of topics\n",
        "print(50/topics) # all good\n",
        "print(ldaobj.beta) # hyperparameter for topics, automatically defined as 200/V, with V the number of unique vocabulary elements\n",
        "print(200/V) # all good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbNY-p-2UuWR",
        "outputId": "4b2609ed-870b-4e26-e581-8b4ddd84b376"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "2.5\n",
            "2.5\n",
            "0.040666937779585195\n",
            "0.040666937779585195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I will sample.\n",
        "\n",
        "To do so, I have to decide on three parameters:\n",
        "\n",
        "\n",
        "1.   Number of iterations we want the chain to burn in before beginning to sample (A)\n",
        "2.   Thinning interval: the number of iterations to let the chain run between samples (B)\n",
        "3.   Number of samples to take (C)\n",
        "\n",
        "Total number of iterations = A + B x C\n",
        "\n"
      ],
      "metadata": {
        "id": "3TWjTuErXLYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = 0\n",
        "B = 50\n",
        "C = 10\n",
        "ldaobj.sample(A,B,C) # Here 500 iterations\n",
        "ldaobj.perplexity() # To check goodness-of-fit of each of the C samples (the lower the value the better the fit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ttHEcrWi75",
        "outputId": "b2371760-a43e-42d9-9bb4-6f3bfdaef504"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10 of (collapsed) Gibbs sampling\n",
            "Iteration 20 of (collapsed) Gibbs sampling\n",
            "Iteration 30 of (collapsed) Gibbs sampling\n",
            "Iteration 40 of (collapsed) Gibbs sampling\n",
            "Iteration 50 of (collapsed) Gibbs sampling\n",
            "Iteration 60 of (collapsed) Gibbs sampling\n",
            "Iteration 70 of (collapsed) Gibbs sampling\n",
            "Iteration 80 of (collapsed) Gibbs sampling\n",
            "Iteration 90 of (collapsed) Gibbs sampling\n",
            "Iteration 100 of (collapsed) Gibbs sampling\n",
            "Iteration 110 of (collapsed) Gibbs sampling\n",
            "Iteration 120 of (collapsed) Gibbs sampling\n",
            "Iteration 130 of (collapsed) Gibbs sampling\n",
            "Iteration 140 of (collapsed) Gibbs sampling\n",
            "Iteration 150 of (collapsed) Gibbs sampling\n",
            "Iteration 160 of (collapsed) Gibbs sampling\n",
            "Iteration 170 of (collapsed) Gibbs sampling\n",
            "Iteration 180 of (collapsed) Gibbs sampling\n",
            "Iteration 190 of (collapsed) Gibbs sampling\n",
            "Iteration 200 of (collapsed) Gibbs sampling\n",
            "Iteration 210 of (collapsed) Gibbs sampling\n",
            "Iteration 220 of (collapsed) Gibbs sampling\n",
            "Iteration 230 of (collapsed) Gibbs sampling\n",
            "Iteration 240 of (collapsed) Gibbs sampling\n",
            "Iteration 250 of (collapsed) Gibbs sampling\n",
            "Iteration 260 of (collapsed) Gibbs sampling\n",
            "Iteration 270 of (collapsed) Gibbs sampling\n",
            "Iteration 280 of (collapsed) Gibbs sampling\n",
            "Iteration 290 of (collapsed) Gibbs sampling\n",
            "Iteration 300 of (collapsed) Gibbs sampling\n",
            "Iteration 310 of (collapsed) Gibbs sampling\n",
            "Iteration 320 of (collapsed) Gibbs sampling\n",
            "Iteration 330 of (collapsed) Gibbs sampling\n",
            "Iteration 340 of (collapsed) Gibbs sampling\n",
            "Iteration 350 of (collapsed) Gibbs sampling\n",
            "Iteration 360 of (collapsed) Gibbs sampling\n",
            "Iteration 370 of (collapsed) Gibbs sampling\n",
            "Iteration 380 of (collapsed) Gibbs sampling\n",
            "Iteration 390 of (collapsed) Gibbs sampling\n",
            "Iteration 400 of (collapsed) Gibbs sampling\n",
            "Iteration 410 of (collapsed) Gibbs sampling\n",
            "Iteration 420 of (collapsed) Gibbs sampling\n",
            "Iteration 430 of (collapsed) Gibbs sampling\n",
            "Iteration 440 of (collapsed) Gibbs sampling\n",
            "Iteration 450 of (collapsed) Gibbs sampling\n",
            "Iteration 460 of (collapsed) Gibbs sampling\n",
            "Iteration 470 of (collapsed) Gibbs sampling\n",
            "Iteration 480 of (collapsed) Gibbs sampling\n",
            "Iteration 490 of (collapsed) Gibbs sampling\n",
            "Iteration 500 of (collapsed) Gibbs sampling\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1006.53767984,  959.4282677 ,  950.79146066,  946.09960784,\n",
              "        944.05912369,  942.03987524,  938.30066595,  935.34240095,\n",
              "        934.96201092,  932.48883449,  931.23533482,  929.50925053,\n",
              "        929.62782345,  928.17487962,  928.03376475,  927.19843967,\n",
              "        925.9422582 ,  927.29631926,  928.47696496,  927.47725147])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I need to use a convergence criterion to decide how many iterations I should use based on a minimized perplexity (like stop when perplexity does not improve by more than 10^-2...)"
      ],
      "metadata": {
        "id": "UnNwhBdeY6zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping the last n samples (as they are the ones with the lowest perplexity, n is arbitrary)\n",
        "n = 4\n",
        "ldaobj.samples_keep(n)"
      ],
      "metadata": {
        "id": "n9E3z2BDYoZH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us look at the shape:\n",
        "    # of my estimated topics\n",
        "print(ldaobj.tt.shape)\n",
        "    # of my estimated document-topic distributions\n",
        "print(ldaobj.dt.shape)"
      ],
      "metadata": {
        "id": "vm0XEp2sZc7m",
        "outputId": "9051b84a-28eb-40d9-d7da-e1dc39bb7cc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4918, 20, 4)\n",
            "(10260, 20, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now I will extract a csv file containing the first m stems in each topic ranked according their probability, using the final stored sample\n",
        "m = 20\n",
        "ldaobj.topic_content(m)"
      ],
      "metadata": {
        "id": "bwS5r0hyaUjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if topics are reasonable: ..."
      ],
      "metadata": {
        "id": "_D3uA9xOahax"
      }
    }
  ]
}